\section{Perturbative Expansion}

The free theory corresponds to a gaussian path integral, which is exactly solvable. With interactions, one is often unable to compute exactly the path integral, and one must resort to some sort of approximation. The simplest one is the perturbative expansion around a free theory, which consists in expanding the solution in power series of the coupling constants that parametrize the interactions. If the couplings are small enough, the perturbative expansion might give a good approximation of the solution.

We describe the perturbative expansion taking as a guiding example the \textbf{anharmonic oscillator}
\[
    S[x] = \int \d{t} \left( \frac{m}{2} \dot{x}^2 - \frac{m\omega^2}{2} x^2 -\frac{g}{3!} x^3 - \frac{\lambda}{4!} x^4 \right),
\]
where if the coupling constants \(g\) and \(\lambda\) vanish, the theory is exactly solvable. Thus, one may try to include perturbatively the corrections that arise when \(g\) and \(\lambda\) are small enough. It is convenient to split the action as the sum of two terms, a free part \(S_0\) which is exactly solvable and an interacting part \(S_{int}\)
\[
    \begin{aligned}
        S[x]       & = S_0[x] + S_{int}[x],                                                       \\
        S_0[x]     & = \int \d{t} \left( \frac{m}{2} \dot{x}^2 - \frac{m\omega^2}{2} x^2 \right), \\
        S_{int}[x] & = \int \d{t} \left( -\frac{g}{3!} x^3 - \frac{\lambda}{4!} x^4 \right).
    \end{aligned}
\]
The perturbative expansion is easily generated in the path integral setup. Including a source term, one expands in a Taylor series the exponential of the interaction term
\[
    \begin{aligned}
        Z[J] & = \int \mathrm{D}x\, e^{\frac{i}{\hbar}\left(S[x]+\int \d{t}Jx\right)} = \int \mathrm{D}x\, e^{\frac{i}{\hbar}S_{int}[x]}e^{\frac{i}{\hbar}\left(S_{0}[x]+\int \d{t}Jx\right)} \\
             & = \int \mathrm{D}x\, \left[ \sum_{n=0}^{\infty} \frac{1}{n!} \left(\frac{i}{\hbar}S_{int}[x]\right)^n \right] e^{\frac{i}{\hbar}\left(S_0[x]+\int \d{t}J x\right)}.
    \end{aligned}
\]
We can keep terms until we are satisfied with the resolution (depending on the entity of \(g\) and \(\lambda\)). Written in the last form, one proceeds in computing it term by term with the use of the Wick’s theorem. It can be written also in the form
\[
    Z[J] = \langle e^{\frac{i}{\hbar} S_{int}[x]} \rangle_{U,0,J},
\]
where the subscripts \(U,\,0,\,J\) denote unnormalized averaging \((U)\) in the free theory \((0)\) with an arbitrary source \((J)\). This expression is sometimes called the \textbf{“Dyson formula”}. It generates the perturbative expansion which can be depicted with \textit{Feynman diagrams}, as we shall see.

An alternative way of writing the perturbative series is the following one
\[
    \begin{aligned}
        Z[J] & = \int \mathrm{D}x\, e^{\frac{i}{\hbar}S_{int}[x]}e^{\frac{i}{\hbar}\left(S_{0}[x]+\int \d{t}Jx\right)}                                                                                                                                                                               \\
             & = \exp\left( \frac{i}{\hbar} S_{int}\left[ \frac{\hbar}{i} \frac{\delta}{\delta J} \right] \right) \int \mathrm{D}x\, e^{\frac{i}{\hbar}\left(S_0[x]+\int \d{t}J x\right)} = \exp\left( \frac{i}{\hbar} S_{int}\left[ \frac{\hbar}{i} \frac{\delta}{\delta J} \right] \right) Z_0[J],
    \end{aligned}
\]
where \(Z_0[J]\) is the generating functional of the free theory. This expression is often more convenient to work with, since it reduces the problem to computing functional derivatives of the known free generating functional. It presents the solution as a (quite complicated) differential operator acting on the functional of the free theory \(Z_0[J]\). In particular, all vacuum diagrams are generated by
\[
    Z[0] = \int \mathrm{D}x\, e^{\frac{i}{\hbar}S[x]} = \exp\left( \frac{i}{\hbar} S_{int}\left[ \frac{\hbar}{i} \frac{\delta}{\delta J} \right] \right) Z_0[J] \Big\vert_{J=0}.
\]
The perturbative expansion can be represented using Feynman diagrams. These are constructed by expanding the interaction term in the path integral and applying Wick’s theorem to compute the correlation functions within the free theory. In these diagrams, vertices, represented as dots, correspond to the interaction potentials and involve a coupling constant multiplied by quantum variables. These variables are paired in all possible combinations using free propagators, which are graphically depicted as lines.

This construction is illustrated below through the example of vacuum diagrams for the anharmonic oscillator.

\subsection{Vacuum Diagrams}

As an example, we compute perturbatively the corrections to the ground state energy of the harmonic oscillator due to the \textbf{anharmonic potential} terms. It is often the case that one computes using the euclidean version of the theory and performs the inverse Wick rotation at the very end to obtain the final result in minkowskian time.

Thus, let us consider the euclidean generating functional and action for the \textbf{anharmonic oscillator}
\[
    \begin{aligned}
        Z_E[J] & = \int \mathrm{D}x\, e^{-\frac{1}{\hbar}\left(S_E[x]-\int \d{\tau} J x\right)},                                                                                          \\
        S_E[x] & = \lim_{\beta \to \infty} \int_{-\beta/2}^{\beta/2} \d{\tau} \left( \frac{m}{2} \dot{x}^2 + \frac{m\omega^2}{2} x^2 + \frac{g}{3!} x^3 + \frac{\lambda}{4!} x^4 \right).
    \end{aligned}
\]
We want to compute corrections to the ground state energy, which can be obtained from the vacuum diagrams, which correspond to \(Z_E[0]\). Using the perturbative expansion, we have
\[
    \begin{aligned}
        Z_E[0] = \int \mathrm{D}x\, e^{-\frac{1}{\hbar}S_{E}[x]} = \langle 1 \rangle_{U} = \lim_{\beta \to \infty} \bra{0} e^{-\beta \hat{H}} \ket{0} = \left\langle e^{-\frac{1}{\hbar} S_{E, int}[x]} \right\rangle_{U,0} = \lim_{\beta \to \infty} e^{-\beta E_0^{(0)}+ \Delta E_0},
    \end{aligned}
\]
where the exact energy \(E_0\) of the ground state \(\ket{0}\) of the anharmonic oscillators differs from the ground state energy of the harmonic oscillator \(E_0^{(0)}\) by the term \(\Delta E_0\) due to the anharmonic potential (here we have the contributions from interaction terms). The correction \(\Delta E_0\) can be computed perturbatively, considering the first non-vanishing corrections to exemplify the perturbative expansion with path integrals and the use of Feynman diagrams.

When we take \(\beta \to \infty\), we are projecting onto the ground state, since we assume that the spectrum of the Hamiltonian is bounded from below. Thus, the euclidean time evolution operator \(e^{-\beta \hat{H}}\) suppresses all contributions from excited states exponentially fast as \(\beta\) increases. Then we apply the perturbative expansion in the interaction term (as we did in Minkowskian time in the previous section), which gives us an unnormalized average in the free theory. Now we can recognize that this average corresponds to the vacuum amplitude of the free theory multiplied by corrections due to the interactions.

We can continue the computation for the interaction terms in the correlation function by considering separately the two terms (by setting each one to zero and effectively \textit{turning off} one interaction at a time). Let us look first at the case with \(g=0\) and focus on the first correction in \(\lambda\) for the \textbf{quartic interaction}:
\[
    \begin{aligned}
        Z_E[0] & = \langle 1 \rangle_U = \left\langle \sum_{n=0}^{\infty} \frac{1}{n!} S_{E,\,int}[x]^n \right\rangle_{U,0} = \langle 1 \rangle_{U,0} -\frac{\lambda}{4!} \int_{-\beta/2}^{\beta/2} \d{\tau} \langle x^4(\tau) \rangle_{U,0} + \cdots                 \\
               & = \langle 1 \rangle_{U,0} \left[ 1 -\frac{\lambda}{4!} \int_{-\beta/2}^{\beta/2} \d{\tau} \langle x^4(\tau) \rangle_{U,0} +\cdots \right] = \langle 1 \rangle_{U,0} \left[ 1 -\frac{\lambda}{4!} \left( 3\times \feynEight \right) + \cdots \right].
    \end{aligned}
\]
In the last line, we have used Wick contractions to calculate normalized correlation functions in the free theory, and then introduced a graphical representation in terms of \textbf{Feynman diagrams}. In this graphical representation, a line denotes a propagator that joins two points in time, while vertices arising from the interactions are denoted by dots. The term we obtained contains just one vertex where four lines can enter or exit, corresponding to the power four of the dynamical variable \(x(\tau)\) associated to the interaction under consideration.

Recalling the euclidean propagator calculated in eq. \eqref{eq:euclidean_green_function_harmonic_oscillator}
\[
    G_E(\tau - \tau^{\prime}) = \langle x(\tau) x(\tau^{\prime}) \rangle_0 = \frac{1}{2\omega} e^{-\omega \vert \tau - \tau^{\prime} \vert} = \feynLine
\]
where this is the \textbf{Feynman Line} associated to the two point correlation function; we can compute the value of the previous diagram, considering that we have four fields at the same time \(\tau\). Thus, we have to consider all possible Wick contractions, which give three identical contributions (we have \(x(\tau)^4\) not \(x_1(\tau)x_2(\tau)\cdots\) so the fields are identical), each corresponding to a pair of propagators that start and end at the same time \(\tau\). Therefore, we have
\[
    DIAGRAMS \quad SUM
\]
So that we understand why we wrote \(3 \times \feynEight\) in the previous expression. Now, we can compute the value of the diagram \(\feynEight\) understanding it as a loop with two propagators that start and end at the same time:
\[
    \feynEight = \int_{-\beta/2}^{\beta/2} \d{\tau} \, G_E(\tau,\tau)^2 = \int_{-\beta/2}^{\beta/2} \d{\tau} \, \left( \frac{1}{2\omega} \right)^2 = \frac{\beta}{4\omega^2}.
\]
Thus, up to this order (first term) in perturbation theory, we have\footnote{This computation relies on the boundaries conditions we have set: with \(\beta \to  \infty\) we are projected on the ground state, and the propagator is computed with this precise Green function, while different boundary conditions would lead to different propagators and thus different results.}
\[
    Z_E[0] = \langle 1 \rangle_{U,0} \left[ 1 - \frac{\lambda}{4!} \left( 3 \times \frac{\beta}{4\omega^2} \right) + \cdots \right] = \langle 1 \rangle_{U,0} \exp\left( -\beta \frac{\lambda}{32\omega^2} + \cdots \right),
\]
so that we can read the correction to the ground state energy due to the quartic interaction
\[
    \Delta E_0 = \frac{1}{32} \frac{\lambda}{\omega^2}.
\]

Similarly, one may consider the case with \(g \neq 0\) and \(\lambda = 0\). The first non-vanishing correction in the \textbf{cubic interaction} arises from:
\[
    \begin{aligned}
        Z_E[0] & = \langle 1 \rangle_U = \left\langle \left( 1- S_{E,\,int} + \frac{1}{2}S_{E,\,int}^2 + \cdots \right) \right\rangle_{U,0}                                                                                                                                                  \\
               & = \langle 1 \rangle_{U,0} + \frac{g}{3!} \int_{-\beta/2}^{\beta/2} \d{\tau} \langle x^3(\tau)\rangle_{U,0} + \frac{g^2}{2(3!)^2} \int_{-\beta/2}^{\beta/2} \d{\tau} \int_{-\beta/2}^{\beta/2} \d{\tau^{\prime}} \langle x^3(\tau) x^3(\tau^{\prime}) \rangle_{U,0} + \cdots \\
               & = \langle 1 \rangle_{U,0} \left[ 1 + 0 + \frac{g^2}{2(3!)^2}\left((3!)\times \feynSunset + (3^2)\times \feynDumbbell \right) + \cdots \right].
    \end{aligned}
\]
The first correction vanishes because there is no way to contract three fields at the same time in pairs (from Wick's theorem). The second correction is represented by a six-point correlation function, which gives two types of contributions: we have three fields at time \(\tau\) and three fields at time \(\tau^{\prime}\), which can be contracted in two different ways.
\[
    DIAGRAMS \quad SUM
\]
The first one has two vertices and three propagators connecting them (in \(3\times 2\times 1\) possible permutations), while the second one has two vertices connected by a single propagator (the two vertices can be chosen from any of the present, so \(3\times 3\) possibilities), with each vertex having a loop attached to it. We can check the combinatorial factors by counting the number of Wick contractions that give rise to each diagram: \(6+9 = 15\), which is indeed the number of ways to contract six fields in pairs.

Thus we have found two types of diagrams: one is the \textbf{sunset diagram} \(\feynSunset\) where two vertices are connected by three propagators, while the other one is the \textbf{dumbbell diagram} \(\feynDumbbell\) where two vertices are connected by a single propagator and each vertex has a loop attached to it. The combinatorial factors arise from the number of Wick contractions that give rise to each diagram. We can compute their values as follows. For the sunset diagram, we have\footnote{We do not compute the limit for \(\beta \to \infty\) yet, since we are just interested in the value of the diagram itself. We will take the limit at the very end to extract the ground state energy correction after inserting these results into the expression for \(Z_E[0]\).}
\[
    \begin{aligned}
        \feynSunset & = \int_{-\beta/2}^{\beta/2} \d{\tau} \int_{-\beta/2}^{\beta/2} \d{\tau^{\prime}} \, G_E(\tau,\tau^{\prime})^3 = \int_{-\beta/2}^{\beta/2} \d{\tau} \int_{-\beta/2}^{\beta/2} \d{\tau^{\prime}} \, \left( \frac{1}{2\omega} e^{-\omega \vert \tau - \tau^{\prime} \vert} \right)^3 \\
                    & = \frac{1}{8\omega^3} \int_{-\beta/2}^{\beta/2} \d{\tau} \int_{-\infty}^{\infty} \d{\sigma} \, e^{-3\omega \sigma} = \frac{\beta}{8\omega^3} 2 \int_{0}^{\infty} \d{\sigma} \, e^{-3\omega \sigma}                                                                                \\
                    & = \frac{\beta}{8\omega^3} 2 \left. \frac{e^{-3\omega \sigma}}{-3\omega} \right|_0^\infty = \frac{\beta}{8\omega^3}\frac{2}{3\omega} = \frac{\beta}{12\omega^4},
    \end{aligned}
\]
while for the dumbbell diagram, we have
\[
    \begin{aligned}
        \feynDumbbell & = \int_{-\beta/2}^{\beta/2} \d{\tau} \int_{-\beta/2}^{\beta/2} \d{\tau^{\prime}} \, G_E(\tau-\tau) G_E(\tau - \tau^{\prime}) G_E(\tau^{\prime} - \tau^{\prime})                                      \\
                      & = \int_{-\beta/2}^{\beta/2} \d{\tau} \int_{-\beta/2}^{\beta/2} \d{\tau^{\prime}} \, \left( \frac{1}{2\omega} \right)^2 \left( \frac{1}{2\omega} e^{-\omega \vert \tau - \tau^{\prime} \vert} \right) \\
                      & = \frac{\beta}{4\omega^2} 2 \int_{0}^{\infty} \d{\sigma} \, \frac{1}{2\omega} e^{-\omega \sigma} = \frac{\beta}{4\omega^2} 2 \left. \frac{e^{-\omega \sigma}}{-\omega} \right|_0^\infty              \\
                      & = \frac{\beta}{8\omega^3}\frac{2}{\omega} = \frac{\beta^2}{4\omega^4}.
    \end{aligned}
\]
Now, we can insert these results into the expression for \(Z_E[0]\) to obtain
\[
    Z_E[0] = \langle 1 \rangle_{U,0} \left[ 1 + \frac{g^2}{2(3!)^2} \left( (3!) \times \frac{\beta}{12\omega^4} + (3^2) \times \frac{\beta^2}{4\omega^4} \right) + \cdots \right] = \langle 1 \rangle_{U,0} \exp\left( \beta \frac{11}{8(3!)^2} \frac{g^2}{\omega^4} + \cdots \right),
\]
finding the entity of the correction to the ground state energy due to the cubic interaction
\[
    \Delta E_0 = - \frac{11}{288} \frac{g^2}{\omega^4}.
\]

\subsection{Other Correlators and Feynman Diagrams}
In a similar way, one computes the perturbative expansion of other correlation functions, considering that the vacuum diagrams correspond to unnormalized 0-point function, relating to the ground state energy. We start from the vacume, something happens during the evolution, and we return to the vacuum.

We can treat the two point correlation function in a similar way. We have two particles, one in the far past and one in the far future, which interacts in some way (for example the anharmonic potential seen before) during their evolution. The two point correlation function is given by
\[
    \begin{aligned}
        \langle x(t_1) x(t_2) \rangle & = \frac{1}{Z} \int \mathrm{D}x\, x(t_1) x(t_2) e^{\frac{i}{\hbar}S[x]} = \left\langle x(t_1) x(t_2) e^{\frac{i}{\hbar} S_{int}[x]} \right\rangle_{0}              \\
                                      & = \left\langle x(t_1) x(t_2) \left[ 1 + \frac{i}{\hbar} S_{int}[x] + \frac{1}{2!} \left( \frac{i}{\hbar} S_{int}[x] \right)^2 + \cdots \right] \right\rangle_{0}.
    \end{aligned}
\]
We can interpret as follows: we have two external points at times \(t_1\) and \(t_2\) where particles are created/annihilated, and we have to consider all possible interactions that may happen during their evolution. Using Wick contractions, we can compute the perturbative expansion of this correlation function in the free theory. For the case of a cubic interaction, \(S_{int} = -\frac{g}{3!}\int\d{t}x(t)^3\), it leads to the following diagrammatic expansion up to second order in perturbation theory:
\[
    DIAGRAMS
\]
its like studying a 8 point function but with 2 external points fixed.
The first diagram corresponds to the free propagator between times \(t_1\) and \(t_2\). The second diagram represents the first-order correction due to a single interaction vertex, where the two external points are connected through a loop. The third and fourth diagrams represent second-order corrections, involving two interaction vertices. The third diagram shows two vertices connected by three propagators, while the fourth diagram has two vertices connected by a single propagator with loops attached to each vertex. This exemplifies how Feynman diagrams arise naturally in the perturbative expansion of correlation functions in quantum field theory.

Let us describe graphically the corrections that must be computed for calculating perturbatively the 4-point function (in a QFT context, it is linked to the scattering of 2 incoming particles to 2 outgoing particles)
\[
    \langle x(t_1) x(t_2) x(t_3) x(t_4) \rangle
\]
where one may keep in mind that setting \(t_1,\,t_2 \to -\infty\) describes incoming states while \(t_3,\,t_4 \to +\infty\) describes outgoing states. We have
\[
    \begin{aligned}
        \langle x(t_1) x(t_2) x(t_3) x(t_4) \rangle & = \frac{1}{Z} \int \mathrm{D}x\, x(t_1) x(t_2) x(t_3) x(t_4) e^{\frac{i}{\hbar}S[x]} = \left\langle x(t_1) x(t_2) x(t_3) x(t_4) e^{\frac{i}{\hbar} S_{int}[x]} \right\rangle_{0} \\
                                                    & = \left\langle x(t_1) x(t_2) x(t_3) x(t_4) \left[ 1 + \frac{i}{\hbar} S_{int}[x] + \frac{1}{2!} \left( \frac{i}{\hbar} S_{int}[x] \right)^2 + \cdots \right] \right\rangle_{0}.
    \end{aligned}
\]

For the case of a cubic interaction, \(S_{int} = -\frac{g}{3!}\int\d{t}x(t)^3\), it leads to the following diagrammatic expansion which is obtained by the systematic use of Wick contractions:\TODO{Modify last diagram in first row, it needs 4 external points.}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{img/diagrammatic_expansion_cubic_interaction.png}
    \caption{Diagrammatic expansion of the 4-point function for a cubic interaction up to second order in perturbation theory.}
    \label{fig:diagrammatic_expansion_cubic_interaction}
\end{figure}

One notices disconnected, connected, and 1PI diagrams, which play a significant role in QFT (1PI diagrams are those diagrams that remain connected after cutting any single internal line). This exemplifies the emergence of Feynman diagrams in describing the perturbative expansion.

Nobody knows what happens during the interaction, virtually anything can happen, but we can sum over all the possibilities using the path integral formalism and Wick’s theorem.

Here ends the treatment for the \textbf{bosonic path integral}: we saw that this formalism aplies naturally on the KG field and scalar fields in general, and we developed the perturbative expansion with Feynman diagrams. In the next section, we extend the path integral formalism to fermionic systems.

\section{Path Integrals for Fermions}

We now discuss how to extend the path integral method to fermionic systems. Fermions at the classical level can be described by \textbf{Grassmann variables}, also known as \textbf{anticommuting} numbers or fermionic variables. Grassmann variables allow us to define “classical” models whose quantization produces degrees of freedom that satisfy the Pauli exclusion principle.

The question is: how can we define a path integral for fermionic systems? The main difficulty arises from the anticommuting nature of fermionic variables, which makes the standard definition of the path integral inapplicable. There is no classical trajectory for fermions in the usual sense, since the ferionic nature of the particles vanishes in the classical limit \(\hbar \to 0\). To overcome this issue, we introduce Grassmann variables to describe fermionic degrees of freedom at the classical level.

We need to introduce a suitable Hamiltonian theory to deal with fermionic degrees of freedom, which has symmetric Poisson Brackets, in order to quantize them canonically obtaining a quantum theory based on \textit{anticommutiors}.
This is why we call it a \textbf{pseudoclassical model}: it is not a classical model in the usual sense, but it is a formal construction that allows us to quantize fermionic degrees of freedom, and leads to the correct quantum theory based on Grassmann variables.
\[
    \left\{ \psi,\,\overline{\psi} \right\}_{C} \longrightarrow \left\{ \hat{\psi},\,\hat{\psi}^\dagger \right\} = i \hbar \dots .
\]
Models with Grassmann variables are often called “pseudoclassical”, as the spin at the classical level is just a formal construction (the value of any finite spin vanishes for \(\hbar \to  0\), and thus cannot be measured classically). In the following, we first exemplify the use of Grassmann variables in mechanical models. The method extends to field theories as well, so that a Dirac field can be treated classically with Grassmann variables. Then, we develop canonical quantization for mechanical models containing Grassmann variables.

At last, we derive a path integral representation of the transition amplitude for fermionic systems starting from its operatorial expression and using a suitable definition of fermionic coherent states.

\subsection{Grassmann Algebras}

A \(n\)-dimensional Grassmann algebra \(\mathcal{G}_n\) is generated by a set of generators \(\theta_i\) with \(i=1,\,\ldots,\,n\), which satisfy the anticommutation relations
\[
    \left\{ \theta_i,\,\theta_j \right\} = \theta_i \theta_j + \theta_j \theta_i = 0, \quad \forall i,\,j = 1,\,\ldots,\,n.
\]
From these relations, it follows that \(\theta_i^2 = 0\) for all \(i\). The elements of the Grassmann algebra are linear combinations of products of the generators, with complex coefficients. This suggests already at the classical level the essence of the Pauli exclusion principle, according to which one cannot put two identical fermions in the same quantum state. Physicists often call these generators anticommuting numbers.

\paragraph{Functions.}
One can multiply these generators and their products by real or complex numbers and form polynomials that are used to define functions of the Grassmann variables (i.e., the elements of the Grassmann algebra). For example, for \(n=1\), there is only one Grassmann variable \(\theta\). Then, an arbitrary function is given by
\[
    f(\theta) = f_0 + f_1 \theta,
\]
where \(f_0\) and \(f_1\) are taken to be either real or complex numbers, and higher power of theta vanish (we can factor a \(\theta^2 = 0\)). Similarly, for \(n=2\) one has
\[
    f(\theta_1,\,\theta_2) = f_0 + f_1 \theta_1 + f_2 \theta_2 + f_{3} \theta_1 \theta_2,
\]
and so on for higher dimensions. A term with \(\theta_2 \theta_1\) is not written as it is not independent of \(\theta_1 \theta_2\), as \(\theta_2 \theta_1 = -\theta_1 \theta_2\). Terms with an even number of \(\theta\)’s are called Grassmann even (or equivalently: even, commuting, bosonic). Terms with an odd number of \(\theta\)’s are called \textit{Grassmann odd} (or equivalently: odd, anticommuting, fermionic). Generic functions are always defined in terms of their Taylor expansions, which contain a finite number of terms because of the Grassmann property. For example, the exponential function \(e^{\theta} \) means \(e^\theta = 1 + \theta\) because \(\theta^2 = 0\) as any other higher power.

\paragraph{Derivatives.}
Derivatives with respect to Grassmann variables are very simple. As any function can be at most linear with respect to any fixed Grassmann variable, its derivative is straightforward and one has to keep track just of signs. \textbf{Left derivatives} are defined by removing the variable from the left of its Taylor expansion: for example for the function \(f(\theta_1, \theta_2)\) given above
\[
    \frac{\partial_L}{\partial \theta_1} f(\theta_1, \theta_2) = f_1 + f_3 \theta_2,
\]
since \(\theta_1\) is removed from the left. Similarly, \textbf{right derivatives} are obtained by removing the variable from the right\footnote{Since before applying the derivative one has to commute the variables until the object of the derivation is in the last position on the right: if it is already there, no sign change occurs.}
\[
    \frac{\partial_R}{\partial \theta_1} f(\theta_1, \theta_2) = f_1 - f_3 \theta_2,
\]
where a minus sign emerges because one has first to commute \(\theta_1\) past \(\theta_2\). One can obtain the same minus sign by left derivatives on \(\theta_2\) using the function of the last example. Equivalently, introducing Grassmann increments \(\delta \theta\), one may write
\[
    \delta f = f(\theta + \delta \theta) - f(\theta) = \delta \theta \frac{\partial_L f}{\partial \theta} = \frac{\partial_R f}{\partial \theta} \delta \theta,
\]
which helps in keeping track of signs. If not specified otherwise, we use left derivatives and omit the corresponding subscript.

\paragraph{Integrals.}
Integration can be defined, according to \textbf{Berezin}, to be identical to differentiation
\[
    \int \d{\theta} = \frac{\partial_L}{\partial \theta}.
\]
This definition has the virtue of producing a \textbf{translational invariant}\footnote{Which, as we have precedently highlighted, is a property we should look for in order to define a consistent thery of integration for our path integrals (think about the previously discussed gaussian integrals).} measure:
\[
    \int \d{\theta} f(\theta + \eta) = \int \d{\theta + \eta} f(\theta + \eta) = \int \d{\tilde{\theta}} f(\tilde{\theta}),
\]
as the measure is translational invariant, \(\d{\theta} = \d{\tilde{\theta}}\) , and \(\tilde{\theta} = \theta + \eta\). This statement is easily proven by a direct calculation
\[
    \int \d{\theta} f(\theta + \eta) = \frac{\partial_L}{\partial \theta} \left( f_0 + f_1 (\theta + \eta) \right) = f_1 = \int \d{\tilde{\theta}} f(\tilde{\theta}),
\]
thus confirming the translational invariance of the measure, which is practically manifest and one of the main reasons for defining integration in this way.

\paragraph{Reality properties.}
Grassmann variables can be defined to be either real or complex. A real variable satisfies
\[
    \overline{\theta} = \theta,
\]
with the bar indicating complex conjugation. For products of Grassmann variables, the complex conjugate is defined to include an exchange of their position
\[
    \overline{\theta_1 \theta_2} = \overline{\theta}_2 \, \overline{\theta}_1.
\]
Thus, the complex conjugate of the product of two real variables is purely imaginary
\[
    \overline{\theta_1 \theta_2} = - \theta_1 \theta_2.
\]
It is the combination \(i \theta_1 \theta_2\) that is real, as the complex conjugate of the imaginary unit carries the additional minus sign to obtain a formally real object
\[
    \overline{i \theta_1 \theta_2} = -i \theta_2 \theta_1 = i \theta_1 \theta_2.
\]
Complex Grassmann variables \(\eta\) and \(\overline{\eta}\) can always be decomposed in terms of two real Grassmann variables \(\theta_1\) and \(\theta_2\) by setting
\[
    \eta = \frac{1}{\sqrt{2}} (\theta_1 + i \theta_2), \quad \overline{\eta} = \frac{1}{\sqrt{2}} (\theta_1 - i \theta_2).
\]
These definitions on the reality properties of the Grassmann variables are the ones that are the most useful for physical applications, since one requires that \textit{real variables become hermitian operators upon quantization}.

\paragraph{Gaussian integrals.}
This integrals are crucial in order to derive the Free theory, first step before moving to a perturbative one. Having defined integration over Grassmann variables, we consider in more detail the gaussian integration, which is at the core of fermionic path integrals. For the case of a single real Grassmann variable \(\theta\) the gaussian function is trivial, \(e^{-a \theta^2} = 1\) , since \(\theta^2=0\) as \(\theta\) anticommutes with itself. One needs at least two real Grassmann variables \(\theta_1\) and \(\theta_2\) to have a nontrivial exponential function with an exponent quadratic in Grassmann
\[
    e^{-a \theta_1 \theta_2} = 1 - a \theta_1 \theta_2,
\]
where \(a\) is either real or complex. With the above definitions, the corresponding “gaussian integral” is computed straightforwardly
\[
    \int \d{\theta_1} \d{\theta_2} e^{-a \theta_1 \theta_2} = \int \d{\theta_1} \d{\theta_2} (1 - a \theta_1 \theta_2) = \frac{\partial_L}{\partial \theta_1} \frac{\partial_L}{\partial \theta_2} (1 - a \theta_1 \theta_2) = a.
\]
Note that there is a precise sign defined by the chosen measure ordering, as \(\int \d{\theta_1} \d{\theta_2} = - \int \d{\theta_2} \d{\theta_1}\). Defining the antisimmmetric matrix
\[
    A = \begin{pmatrix}
        0  & a \\
        -a & 0
    \end{pmatrix}, \quad \det A = a^2,
\]
one may rewrite the previous integral as
\[
    \int \d{\theta_1} \d{\theta_2} e^{-\frac{1}{2} \theta_i A_{ij} \theta_j} = \int \d{\theta_1} \d{\theta_2} e^{-a \theta_1 \theta_2} = a = \sqrt{\det A}.
\]
The square root of the determinant of an antisymmetric matrix A is called the \textbf{Pfaffian}, and often indicated by \(\text{Pfaff}\, A\). Indeed, the determinant is always positive definite for real antisymmetric matrices, and its square root is well-defined (by analytic extensions, it is also well-defined for antisymmetric matrices with complex entries). It is easy to see that the above formula extends to an even number \(n = 2m\) of real Grassmann variables, so that one may write in general
\[
    \int \mathrm{d}^n \theta \, e^{-\frac{1}{2} \theta_i A_{ij} \theta_j} = \text{Pfaff}\, A = \sqrt{\det A},
\]
where \(A\) is a real antisymmetric \(n \times n\) matrix and \(\mathrm{d}^n \theta = \mathrm{d} \theta_1 \cdots \mathrm{d} \theta_n\). This formula is the fermionic counterpart of the bosonic gaussian integral seen before (where if one remember, the square root of the determinant of the matrix at the exponent was inverse: \((\det K)^{-1 / 2}\)), and it plays a crucial role in defining fermionic path integrals.
To prove this, one notices that with an orthogonal transformation one can skew-diagonalize the antisymmetric matrix \(A_{ij}\) and put it in the form
\[
    \begin{pmatrix}
        0      & a_1    & 0      & 0      & \dots  & 0      & 0      \\
        -a_1   & 0      & 0      & 0      & \dots  & 0      & 0      \\
        0      & 0      & 0      & a_2    & \dots  & 0      & 0      \\
        0      & 0      & -a_2   & 0      & \dots  & 0      & 0      \\
        \vdots & \vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
        0      & 0      & 0      & 0      & \dots  & 0      & a_m    \\
        0      & 0      & 0      & 0      & \dots  & -a_m   & 0
    \end{pmatrix}
\]
The orthogonal transformation leaves the integration measure invariant and thus one gets the above result with \((\det A)^{1 / 2} = a_1 \cdots a_m \). A cautionary note: to compute correctly the jacobian under a change of variables one should recall the definition of the integration in terms of derivatives (the Berezin integration), and thus find the inverse matrix with respect to the one associated with an analogous bosonic integral.

Similarly, one finds that gaussian integration over complex Grassmann variables \((\eta_i,\, \overline{\eta}_i)\) produce a determinant
\[
    \int \mathrm{d}^n\overline{\eta} \mathrm{d}^n\eta e^{-\overline{\eta}_i A_{ij} \eta_j} = \det A,
\]
where the measure is now deifined as \(\mathrm{d}^n\overline{\eta} \mathrm{d}^n\eta = \d{\eta_1}\d{\overline{\eta}_1} \cdots \d{\eta_n} \d{\overline{\eta}_n}\).

For applications to dynamical models and subsequent path integral quantization, it is useful to consider infinite dimensional Grassmann algebras (\(n \to \infty\)). Then, one may use Grassmann valued functions of time, i.e. \(\theta_i \to \theta(t)\). For different values of \(t\), one has different generators of the algebra, so that properties such as \(\theta^2(t) = 0\) and \(\theta(t) \theta(t') = - \theta(t') \theta(t)\) hold. They are used to introduce useful mechanical systems at the classical level, often named psudoclassical models, that upon quantization produce systems satisfying the Pauli exclusion principle and the Fermi-Dirac statistic.

\subsection{Pseudoclassical Model and Canonical Quantization}

We are going to exemplify the use of Grassmann variables in mechanical models. We will use the so called \textbf{fermionic oscillator}: if we remember the bosonic harmonic oscillator, we can define its fermionic counterpart by introducing Grassmann variables. For the bosonic harmonic oscillator, we had the action
\[
    S[x,p] = \int \d{t} \left( p \dot{x} - \frac{1}{2} (p^2 + \omega^2 x^2) \right),
\]
which can be rewritten with the complex variables
\[
    a = \frac{1}{\sqrt{2 \omega}} (\omega x + i p), \quad \overline{a} = \frac{1}{\sqrt{2 \omega}} (\omega x - i p),
\]
so that the action becomes
\[
    S[a,\,\overline{a}] = \int \d{t} \left( \frac{i}{2} (\overline{a} \dot{a} - \dot{\overline{a}} a) - \omega \overline{a} a \right).
\]

To define the fermionic counterpart, we introduce two complex Grassmann variables \(\psi\) and \(\overline{\psi}\), and write the action
\[
    S[\psi,\,\overline{\psi}] = \int \d{t} \left( i \overline{\psi} \dot{\psi} - \omega \overline{\psi} \psi \right).
\]
Now if we compute the variation of the action with respect to \(\overline{\psi}\) and \(\psi\), we find the equations of motion
\[
    \delta S = 0 = \int \d{t} \left[ i \delta \overline{\psi} \left( i \dot{\psi} - \omega \psi\right) + \left(- i \dot{\overline{\psi}} - \omega \overline{\psi}\right) \delta \psi \right].
\]
Thus, the equations of motion are
\[
    i \dot{\psi} - \omega \psi = 0, \quad - i \dot{\overline{\psi}} - \omega \overline{\psi} = 0.
\]
[...]
To proceed with canonical quantization, we compute the conjugate momenta
\[
    \pi = \frac{\partial_L L}{\partial \dot{\psi}} = - i \overline{\psi}, \quad \overline{\pi} = \frac{\partial_L L}{\partial \dot{\overline{\psi}}} = 0.
\]
which shows that the system is already in a hamiltonian form, the conjugate momenta being \(\overline{\psi}\) up to a factor. The classical Poisson bracket \(\{\pi,\,\psi\}_{PB} = -1\) is rewritten as \(\{\pi,\,\psi\}_{PB} = -i\), and has the property of being symmetric (this fact will be discussed in a short while).

Quantizing with anticommutators (fermionic systems must be treated this way) one obtains
\[
    \begin{aligned}
        \left\{ \hat{\psi}, \hat{\psi}^{\dagger} \right\}           & = i \hbar (-i) = \hbar, \\
        \left\{ \hat{\psi}, \hat{\psi} \right\}                     & = 0,                    \\
        \left\{ \hat{\psi}^{\dagger}, \hat{\psi}^{\dagger} \right\} & = 0,
    \end{aligned}
\]
that is, the classical variables \(\psi\) and \(\overline{\psi}\) are promoted to linear operators \(\hat{\psi}\) and \(\hat{\psi}^{\dagger}\) satisfying anticommutation relations that are set to be equal to \(i\hbar\) times the value of the classical Poisson brackets. Setting \(\hbar = 1\) for simplicity, one finds the fermionic creation/annihilation algebra
\[
    \left\{\hat{\psi},\,\hat{\psi}^{\dagger}\right\} = 1, \quad \left\{\hat{\psi},\,\hat{\psi}\right\} = \left\{\hat{\psi}^{\dagger},\,\hat{\psi}^{\dagger}\right\} = 0.
\]
that can be realized in a two-dimensional Hilbert space and with the correct hermiticity properties. If we recall the bosonic harmonic oscillator, we had the algebra of ladder operators defined as
\[
    \left[ \hat{a},\,\hat{a}^{\dagger} \right] = 1, \quad \left[ \hat{a},\,\hat{a} \right] = \left[ \hat{a}^{\dagger},\,\hat{a}^{\dagger} \right] = 0,
\]
which is similar to the fermionic one, but with commutators instead of anticommutators. The main difference is that in the bosonic case, the Hilbert space is infinite-dimensional, while in the fermionic case it is two-dimensional, due to the Pauli exclusion principle.

The Hilbert is explicitly constructed "\textit{à la Fock}", considering \(\hat{\psi}\) as destruction operator and \(\hat{\psi}^{\dagger}\) as creation operator. One starts defining the Fock vacuum \(\ket{0}\), fixed by the condition
\[
    \hat{\psi}\ket{0} = 0.
\]
A second state is obtained by acting with \(\hat{\psi}^{\dagger}\)
\[
    \ket{1} = \hat{\psi}^{\dagger}\ket{0}.
\]
No other state can be obtained acting again with the creation operator \(\hat{\psi}^{\dagger}\), since \((\hat{\psi}^{\dagger})^2 = 0\). Thus the Hilbert space is two-dimensional, spanned by the orthonormal basis \(\{ \ket{0},\,\ket{1} \}\), encapsulating the Pauli exclusion principle at the quantum level.

Normalizing the Fock vacuum to unity, \(\bra{0}\ket{0} = 1\), with \(\bra{0} = \ket{0}^{\dagger}\), one finds that these two states are orthonormal
\[
    \bra{n}\ket{m} = \delta_{nm}, \quad n,\,m = 0,\,1,
\]
and span a two-dimensional Hilbert space, \(\mathcal{F}_2 = \left\{ \ket{0},\,\ket{1} \right\}\). In terms of matrices one computes matrix elements and finds the realization
\[
    \begin{aligned}
        \hat{\psi}           & = \begin{pmatrix}
                                     \bra{0}\hat{\psi}\ket{0} & \bra{0}\hat{\psi}\ket{1} \\
                                     \bra{1}\hat{\psi}\ket{0} & \bra{1}\hat{\psi}\ket{1}
                                 \end{pmatrix} = \begin{pmatrix}
                                                     0 & 1 \\
                                                     0 & 0
                                                 \end{pmatrix},                     \\
        \hat{\psi}^{\dagger} & = \begin{pmatrix}
                                     \bra{0}\hat{\psi}^{\dagger}\ket{0} & \bra{0}\hat{\psi}^{\dagger}\ket{1} \\
                                     \bra{1}\hat{\psi}^{\dagger}\ket{0} & \bra{1}\hat{\psi}^{\dagger}\ket{1}
                                 \end{pmatrix} = \begin{pmatrix}
                                                     0 & 0 \\
                                                     1 & 0
                                                 \end{pmatrix}
    \end{aligned}
\]
acting on the basis
\[
    \ket{0} = \begin{pmatrix}
        1 \\
        0
    \end{pmatrix}, \quad \ket{1} = \begin{pmatrix}
        0 \\
        1
    \end{pmatrix}.
\]

\paragraph{Hamiltonian structure.}
The hamiltonian of the fermionic oscillator is obtained from the Legendre transform of the Lagrangian, since we can write the action as
\[
    S[x,\,p] = \int \d{t} \left( p \dot{x} - H(x,\,p) \right) = \int \d{t} \frac{1}{2} \begin{pmatrix}
        x & p
    \end{pmatrix} \begin{pmatrix}
        0 & -1 \\
        1 & 0
    \end{pmatrix} \begin{pmatrix}
        \dot{x} \\
        \dot{p}
    \end{pmatrix} - H(x,\,p) = \int \d{t} \left( 1/2 z^a \left(\Omega^{-1}\right) \dot{z}^b  - H(z) \right).
\]
This action produces the correct equations of motion via Hamilton’s equations, which will be of the first order in time derivatives for fermionic systems. As we can notice the first term in the action is symplectic and involves an antisymmetric matrix, which is the reason why the Poisson brackets for fermionic systems are symmetric (in contrast to bosonic systems, where the symplectic form is given by a symmetric matrix and the Poisson brackets are antisymmetric). This is a general feature of fermionic systems, which can be traced back to the anticommuting nature of Grassmann variables. We can rewrite the action

\begin{example}
    duh
\end{example}

\begin{example}
    duh doi
\end{example}

\begin{example}
    duh trei
\end{example}

\begin{example}
    duh patru
\end{example}

\subsection{Coherent States}

\subsection{Fermionic Path Integrals}

\paragraph{Trace.}

\paragraph{Supertrace.}

\subsection{Correlation Functions}